#机器学习面试的那些事儿
作者：李庆斌
链接：https://zhuanlan.zhihu.com/p/22387312
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

一直想写写数据科学家面试中机器学习有关的问题，无奈杂事缠身又懒癌发作导致迟迟没有动笔。最近找工季来临，不少同学找我咨询数据科学家面试的问题，借此机会把自己的一点点想法和经验教训记录下来。

作为数据科学家的核心技能之一，机器学习在数据科学家日常工作中的重要性不言而喻。正因如此，机器学习是数据科学家面试中极为重要的一环。但是机器学习涵盖范围广，同时涉及诸多复杂的数学知识，精通所有主流算法及其细节对于绝大多数人而言都是很难实现的。同时，机器学习的面试又是一个理论与实践紧密结合的方式，对于初学者来说，无疑大大增加了面试准备的难度。但是，面试并不是考试，对于知识点的侧重与考试也是有所不同，只要准备方法得当，抓住主要矛盾，掌握面试的规律，就能够游刃有余的应对大部分机器学习方面的面试。

接下来我将以垃圾邮件分类器为例，谈一下数据科学家面试中是如何对机器学习进行考察。假设我们做过一个垃圾邮件分类器的项目。为了建立这个分类器，我们首先对数据进行清理及预处理，如缺失数据的处理、数据的归一化等。在获得初始特征向量后，用PCA进行了特征选择。利用特征选择得到的特征向量及对应数据，训练一个随机森林的分类器作为我们的垃圾邮件分类器。针对的这样一个项目，有这样几个点可以进行挖掘和准备。

##1. 项目简介

如何向面试官介绍你做过的项目，这是一个非常基础、非常常见但是又充满技巧的问题。首先，项目简介不应过于冗长，力争用最短的几句话勾勒出项目的框架。其次，数据科学相关项目通常是业务与技术并存，因此，既要突出项目过程中解决的技术难题及应用的相关技术，又应该兼顾项目带来的业务上的影响。

##2. 模型简介

这类问题同样是机器学习面试中最普遍最常见的一类问题，面试的形式一般为介绍一个你最喜欢的模型，或是介绍项目中应用的某种模型。与项目简介相同，模型简介也应力求简洁，用最简短的几句话，讲清楚模型是用了什么样的原理完成了怎样的目标。wikipedia中关于随机森林的定义给我们提供了一个非常好的学习模板，可以用来借鉴：

Random forests is a notion of the general technique of random decision forests that are an ensemble learning method(怎样的方法) for classification, regression and other tasks(解决了什么问题), that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees(基本原理).

但是，wikipedia中大部分模型的描述更偏书面化的表达，并不适合原封不动地照搬到面试中。我们需要将它转化为更口语化的表达。

##3. 模型的优缺点

模型的优缺点与模型简介是紧密相关的，可以将两个问题结合起来一起准备。比如之前我们谈到了什么是随机森林，紧接着可以谈一下随机森林有什么优点，如：a. 对于很多数据集表现良好，精确度比较高；b. 不容易过拟合；c. 可以得到变量的重要性排序；d. 既能处理离散型数据，也能处理连续型数据，且不需要进行归一化处理； e. 能够很好的处理缺失数据；f. 容易并行化等等。同时，将理论与实践结合也是非常好的切入点，如随机森林的诸多优点是如何体现在垃圾邮件分类器项目中，这样的结合能更好的展示出面试人对于模型的理解及掌控。

##4. 模型原理及相关技术细节

模型简介与模型优缺点的问题属于概念性问题，偏向于考察面试人是否了解某种模型，而更进一步的则是对于模型原理及相关技术细节的考察，比如模型假设、目标函数、优化过程、算法收敛性等。所谓知其然，又知其所以然，这是对于面试人的进一步要求。

例如，在模型的优缺点中，我们提到了随机森林可以对变量重要性进行排序。相应地，我们应该能够解释随机森林是如何对变量重要性进行排序，有哪几种常见的排序指标，比如利用OOB误分率的改变或者分裂时信息增益的变化等。当然，问题并非到此终止，基于上面提到的两种常见的变量重要性排序指标，又可以衍生出新的问题。例如，针对OOB误分率这个指标，解释一下什么是OOB，随机森林中OOB是如何计算的，它有什么样的优缺点；针对信息增益，同样会有很多与之有关的问题，如什么是信息增益，如何计算信息增益，什么是熵，什么是GINI指数，他们之间的区别是什么，他们之间的区别会对建树产生怎样的影响等。

再如，在垃圾邮件分类器项目中，有一部分数据存在缺失，而随机森林具有处理缺失数据的优点，建模的过程中我们充分利用了这一特性。那么，与之相关的问题可能会是，随机森林为什么会有这个优点？随机森林是怎样对缺失数据进行训练及预测？

##5. 模型的横向比较

模型原理及相关技术细节的考察属于对机器学习知识深度考察的范畴，与之对应的是机器学习知识广度方面的考察。广度上的考察主要有两大部分，一方面是从理论上对不同算法进行横向比较，如模型假设，优化方法等。另一方面，是结合实际案例对不同算法进行横向比较，这要求面试人不仅仅要熟知不同模型的原理及技术细节，更需要将抽象的理论与具体的实践结合，在实际案例中对算法进行比较。

在垃圾邮件分类器项目中，随机森林被用作最终的分类器模型。面试官可能会就此提出以下问题：为什么选择随机森林而非其他模型，比如朴素贝叶斯或者支持向量机。一般来说，面试者可以从数学理论和工程实现两个方面进行比较回答。从理论上讲，数据表现出来的特征，以及模型所基于的假设都是很好的突破口;从工程实现上讲，实现的难易程度，是否易于scale都是可以考虑的点。

##6. 开放性问题

除了对机器学习知识深度和广度上的考察，开放性问题也是面试中经常会遇到的问题，对于初学者来说这也是最难准备的一类问题。一方面这类问题很难在教科书中见到，没有固定的问题清单；另一方面，这类问题没有标准答案，很多时候是对过往经验的总结。针对这一类问题，更多的是靠平时工作学习过程中多思考、多总结、多积累，临阵抱佛脚很难起到效果。

再次回到垃圾邮件分类器项目，这个项目中有多个开放性问题可以被提问。比如，1. 邮件数据存在缺失，通常情况下，如何对缺失数据进行处理？2. 垃圾邮件分类是一个非平衡数据集分类的问题，针对这一类问题，我们应该如何进行建模。3. 项目中，PCA被用于特征选择，除此而外，还有哪些方法可以用来进行特征选择？

##7. 准备材料

在准备机器学习的过程中，我主要用了如下的材料：

A. Stanford CS229 Machine Learning.

B. CMU 10-701 Introduction to Machine Learning.

C. The Elements of Statistical Learning. By Trevor Hastie, Robert Tibshirani and Jerome Friedman.

D. Pattern Recognition and Machine Learning. By Christopher Bishop.

A.和B.是Stanford和CMU机器学习课程的课件，里面涵盖了各种常用算法，应该力求掌握这些算法。C.和D.是经典中的经典，难度适中，内容没有太理论，语言也没有太晦涩，是机器学习内功修炼的不二法门。
关于材料再说句题外话，我之前是个资料收集整理爱好者，总是在努力充实自己的资料库，总是担心遗漏任何有用的材料。但是后来才逐渐意识到，资料求精不求多，存在脑子里面的叫知识，存在硬盘里叫文档。
